================ Training Loss (Tue Nov 20 10:27:16 2018) ================
================ Training Loss (Tue Nov 20 10:28:22 2018) ================
================ Training Loss (Tue Nov 20 10:29:14 2018) ================
================ Training Loss (Tue Nov 20 10:30:30 2018) ================
================ Training Loss (Tue Nov 20 10:32:29 2018) ================
================ Training Loss (Tue Nov 20 10:33:11 2018) ================
================ Training Loss (Tue Nov 20 10:35:14 2018) ================
(epoch: 1, iters: 1000, time: 0.099) d0: 0.472 d1: 0.012 d2: 0.015 d3: 0.002 d4: 0.002 d5: 0.001 d6: 0.001 d7: 0.096 d8: 0.006 
================ Training Loss (Tue Nov 20 10:38:15 2018) ================
(epoch: 1, iters: 1000, time: 0.064) d0: 0.476 d1: 0.004 d2: 0.006 d3: 0.001 d4: 0.002 d5: 0.001 d6: 0.001 d7: 0.026 d8: 0.006 
(epoch: 1, iters: 2000, time: 0.061) d0: 0.757 d1: 0.015 d2: 0.013 d3: 0.000 d4: 0.000 d5: 0.001 d6: 0.001 d7: 0.188 d8: 0.020 
================ Training Loss (Tue Nov 20 10:43:02 2018) ================
(epoch: 1, iters: 1000, time: 0.062) d0: 0.471 d1: 0.004 d2: 0.005 d3: 0.003 d4: 0.004 d5: 0.000 d6: 0.000 d7: 0.076 d8: 0.006 
(epoch: 1, iters: 2000, time: 0.062) d0: 0.746 d1: 0.001 d2: 0.000 d3: 0.001 d4: 0.001 d5: 0.001 d6: 0.001 d7: 0.067 d8: 0.015 
(epoch: 1, iters: 3000, time: 0.060) d0: 0.889 d1: 0.015 d2: 0.009 d3: 0.007 d4: 0.004 d5: 0.000 d6: 0.000 d7: 0.276 d8: 0.025 
